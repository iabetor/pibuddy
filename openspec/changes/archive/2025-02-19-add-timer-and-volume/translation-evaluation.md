# 翻译功能评估报告

## 1. 功能概述

为 PiBuddy 添加语音翻译功能，用户可以说：
- "把'你好'翻译成英语"
- "How are you 用中文怎么说"
- "翻译一下这句话：..."

## 2. 技术方案对比

### 方案 A：在线翻译 API

| 服务 | 免费额度 | 优点 | 缺点 |
|------|----------|------|------|
| **百度翻译** | 5万字符/月 | 中文优化、稳定 | 需注册、有配额限制 |
| **腾讯翻译君** | 500万字符/月 | 中文优化、额度大 | 需腾讯云账号 |
| **有道翻译** | 1000次/小时 | 中文优化 | 频率限制严格 |
| **Google Translate** | 有限 | 语言最多 | 国内不可用、需代理 |
| **DeepL** | 50万字符/月 | 质量最高 | 中文支持有限、需代理 |

**推荐**：腾讯翻译君（额度大、中文优化、与现有腾讯云 TTS 统一账号）

**实现复杂度**：⭐（低）

```go
// 调用示例
type TranslateTool struct {
    secretID  string
    secretKey string
}

func (t *TranslateTool) Execute(ctx context.Context, args json.RawMessage) (string, error) {
    // 调用腾讯云机器翻译 API
    // https://cloud.tencent.com/document/api/551/15619
}
```

---

### 方案 B：LLM 直接翻译

利用现有 LLM 能力，通过 prompt 实现翻译：

```
System Prompt 补充：
你具备翻译能力。当用户要求翻译时，直接输出翻译结果，不要解释。
```

**优点**：
- 无需额外 API
- 实现成本为零
- 支持更多语言和语境

**缺点**：
- 响应延迟高（需要 LLM 推理）
- Token 消耗增加成本
- 翻译质量不如专业服务

**实现复杂度**：⭐（最低）

---

### 方案 C：本地离线翻译

使用开源离线翻译模型：

| 项目 | 模型大小 | 语言支持 | 树莓派可行性 |
|------|----------|----------|--------------|
| **Argos Translate** | ~500MB/语言对 | 多语言 | 可行但较慢 |
| **MarianMT (ONNX)** | ~300MB/语言对 | 多语言 | 可行 |
| **NLLB (量化)** | ~1GB | 200+语言 | 内存不足 |

**优点**：
- 完全离线
- 无网络依赖

**缺点**：
- 模型体积大
- 树莓派推理慢（2-5秒）
- 中文翻译质量一般

**实现复杂度**：⭐⭐⭐（高）

---

## 3. 推荐方案

### 主方案：LLM 直接翻译（立即可用）

**理由**：
1. **零成本**：复用现有 LLM 连接
2. **零开发**：只需更新 system prompt
3. **零依赖**：不需要新的 API Key 或模型
4. **高质量**：DeepSeek 等中文 LLM 翻译质量不错

**System Prompt 补充**：
```yaml
system_prompt: |
  ...
  
  【翻译能力】
  当用户要求翻译时：
  1. 识别源语言和目标语言
  2. 直接输出翻译结果
  3. 不要添加解释或额外说明
  4. 示例：
     用户："把'你好世界'翻译成英语"
     回复："Hello World"
```

### 备选方案：腾讯翻译君 API（需要时再接入）

**触发条件**：
- 用户反馈翻译响应太慢
- 翻译需求频繁（影响 LLM 成本）
- 需要更专业的翻译质量

---

## 4. 性能影响分析

| 指标 | LLM 翻译 | 腾讯 API | 离线模型 |
|------|----------|----------|----------|
| 响应延迟 | 1-3秒 | 200-500ms | 2-5秒 |
| 内存占用 | 0（复用） | 0 | 500MB+ |
| Token 成本 | 有 | 无 | 无 |
| 网络依赖 | 有 | 有 | 无 |
| 中文质量 | 良好 | 优秀 | 一般 |

---

## 5. 维护成本

| 方案 | 维护工作 |
|------|----------|
| LLM 翻译 | 无（prompt 调整） |
| 腾讯 API | API Key 管理、额度监控 |
| 离线模型 | 模型更新、磁盘空间管理 |

---

## 6. 结论

**建议先采用 LLM 直接翻译**：
1. 更新 system prompt 即可启用
2. 无需任何代码开发
3. 后续可根据用户反馈决定是否接入专业翻译 API

**如果需要独立工具**（便于统计、限流等），可创建 `TranslateTool`，内部调用 LLM：
```go
func (t *TranslateTool) Execute(ctx context.Context, args json.RawMessage) (string, error) {
    var a struct {
        Text       string `json:"text"`
        TargetLang string `json:"target_lang"`
    }
    // 调用 LLM with specific prompt
    prompt := fmt.Sprintf("将以下内容翻译成%s，只输出翻译结果：%s", a.TargetLang, a.Text)
    return t.llmClient.Chat(ctx, prompt)
}
```

---

## 7. 决策建议

| 场景 | 推荐方案 |
|------|----------|
| 快速上线、低成本 | LLM 直接翻译 ✅ |
| 追求速度、专业质量 | 腾讯翻译 API |
| 完全离线场景 | 不建议（树莓派性能限制） |

**我的建议**：先不开发独立的翻译工具，通过更新 system prompt 让 LLM 具备翻译能力。后续如用户反馈需要，再开发专门的翻译工具。
